{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "m_path = os.path.abspath(os.path.join(\"..\\..\"))\n",
    "if m_path not in sys.path:\n",
    "    sys.path.append(m_path)\n",
    "    \n",
    "from rigging.weight_transfer import main\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smplx_.body_models import SMPL\n",
    "\n",
    "smpl = SMPL(\"../../smpl\", gender=\"male\")\n",
    "src_weights = smpl.lbs_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "src_dict_path = \"../no_git_test_data/16-14/16-14.pkl\"\n",
    "\n",
    "with open(src_dict_path, \"rb\") as f:\n",
    "    src_dict = pickle.load(f)\n",
    "\n",
    "pose = src_dict['pose']\n",
    "trans = src_dict['trans']\n",
    "scale = src_dict['scale']\n",
    "\n",
    "with torch.no_grad():\n",
    "    fin_pose= torch.FloatTensor(pose).unsqueeze(0)\n",
    "    smpl_output, T = smpl(\n",
    "        global_orient=fin_pose[:, :3], \n",
    "        body_pose=fin_pose[:, 3:]\n",
    "    )\n",
    "\n",
    "    ret_verts = smpl_output.vertices\n",
    "    ret_joints = smpl_output.joints\n",
    "\n",
    "    trans_verts = ret_verts.squeeze() #* scale + trans\n",
    "    trans_joints = ret_joints.squeeze() #* scale + trans\n",
    "\n",
    "smpl_mesh = o3d.geometry.TriangleMesh()\n",
    "smpl_mesh.vertices = o3d.utility.Vector3dVector(trans_verts)\n",
    "smpl_mesh.triangles = o3d.utility.Vector3iVector(smpl.faces.astype(int))\n",
    "smpl_mesh.compute_vertex_normals()\n",
    "\n",
    "joints = trans_joints[:24]\n",
    "joints_pt = o3d.geometry.PointCloud()\n",
    "joints_pt.points = o3d.utility.Vector3dVector(joints)\n",
    "joints_pt.colors = o3d.utility.Vector3dVector(np.repeat([[0, 0, 1]], repeats=joints.shape[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _, original_T = smpl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glb_path = \"C:/Users/User/Downloads/smpl_male_blend2.glb\"\n",
    "# glb = o3d.io.read_triangle_mesh(glb_path)\n",
    "\n",
    "# o3d.visualization.draw_geometries([glb, o3d.geometry.LineSet.create_from_triangle_mesh(smpl_mesh)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_mesh_path = \"../no_git_test_data/1-1/smpl1.obj\"\n",
    "target_mesh_path = \"../no_git_test_data/16-14/model_cleaned.obj\"\n",
    "\n",
    "# src_mesh = o3d.io.read_triangle_mesh(source_mesh_path)\n",
    "tgt_mesh = o3d.io.read_triangle_mesh(target_mesh_path, True)\n",
    "# tgt_mesh.compute_vertex_normals()\n",
    "# align with smpl\n",
    "tgt_mesh.vertices = o3d.utility.Vector3dVector(np.asarray(tgt_mesh.vertices) / scale - trans + smpl_output.joints[:, 0].cpu().numpy())\n",
    "\n",
    "o3d.visualization.draw_geometries([o3d.geometry.LineSet.create_from_triangle_mesh(smpl_mesh), joints_pt, tgt_mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\CODE\\FYP\\models\\rigging\\weight_transfer.py:319: RuntimeWarning: invalid value encountered in divide\n",
      "  W = W / W.sum(axis=1, keepdims=True) + 1e-8\n"
     ]
    }
   ],
   "source": [
    "tgt_weights, v_match, v_no_match = main(smpl_mesh, tgt_mesh, src_weights.cpu().numpy(), threshold_distance=0.5/scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132078, 24)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.zeros((tgt_weights.shape[0], 3))\n",
    "colors[v_match] = np.array([0., .5, 0.])\n",
    "colors[v_no_match] = np.array([.5, 0., 0])\n",
    "tgt_mesh.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "tgt_mesh.triangle_uvs = o3d.utility.Vector2dVector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([joints_pt, tgt_mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaolin.metrics.trianglemesh import point_to_mesh_distance\n",
    "from trimesh.triangles import points_to_barycentric\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "def comupte_transform(\n",
    "    target: torch.Tensor, \n",
    "    vertices: torch.Tensor,\n",
    "    faces: torch.Tensor, \n",
    "    T: torch.Tensor,\n",
    "    device: torch.device = torch.device(\"cuda\")\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"compute tranformation matrix for each vertex in the target mesh \n",
    "    by finding the closest point on the reference faces.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : torch.Tensor\n",
    "        the vertices to compute the transformation for.\n",
    "        [n, 3]\n",
    "    vertices : torch.Tensor\n",
    "        the vertices in 3d position of the reference mesh\n",
    "        [m, 3]\n",
    "    faces : torch.Tensor\n",
    "        the faces in vertex indeice of the reference mesh\n",
    "        [f, 3]\n",
    "    T: torch,.Tensor\n",
    "        the transformation matices of each vertex\n",
    "        [m, 4, 4]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        the computed tranformation matrix of shape [n, 4, 4]\n",
    "    \"\"\"\n",
    "\n",
    "    face_positions = vertices[faces]\n",
    "    _, face_ids, _ = point_to_mesh_distance(\n",
    "        target.to(device=device).unsqueeze(0),\n",
    "        face_positions.to(device=device).unsqueeze(0))\n",
    "    face_ids = face_ids.squeeze().to(device=target.device)\n",
    "    \n",
    "    bary_coords = points_to_barycentric(face_positions[face_ids], target)\n",
    "    ref_T = T[faces[face_ids]]\n",
    "    target_T = (bary_coords * ref_T).sum(axis=1)\n",
    "    \n",
    "    return target_T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt_T = comupte_transform(\n",
    "#     torch.as_tensor(np.asarray(tgt_mesh.vertices)),\n",
    "#     torch.as_tensor(np.asarray(smpl_mesh.vertices)),\n",
    "#     torch.as_tensor(np.asarray(smpl_mesh.triangles, dtype=int)),\n",
    "#     T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbs(W, T, V, inverse=False):\n",
    "    V_homo = torch.concat([V, torch.ones((V.shape[0], 1), device=V.device)], dim=-1).unsqueeze(dim=-1)\n",
    "    T = (W @ T).view(-1, 4, 4)\n",
    "    if inverse:\n",
    "        T = torch.linalg.inv(T)\n",
    "    V_homo = T @ V_homo\n",
    "    return V_homo[:, :3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcloth.components.utils import create_o3d_pcd\n",
    "\n",
    "device = \"cuda\"\n",
    "W = torch.as_tensor(tgt_weights, device=device).to(dtype=torch.float32)\n",
    "T0 = T.to(device=device)\n",
    "T1 = original_T.cuda()\n",
    "V = torch.as_tensor(np.asarray(tgt_mesh.vertices), device=device).to(dtype=torch.float32)\n",
    "V_norm = lbs(W, T0, V, inverse=True)\n",
    "\n",
    "W_smpl = src_weights.cuda()\n",
    "V_smpl = torch.as_tensor(np.asarray(smpl_mesh.vertices), device=device).to(dtype=torch.float32)\n",
    "v_smpl_norm = lbs(W_smpl, T0, V_smpl, inverse=True)\n",
    "\n",
    "pcd1 = create_o3d_pcd(lbs(W, T1, V_norm).detach().cpu())\n",
    "pcd2 = create_o3d_pcd(v_smpl_norm.cpu().numpy(), colors=np.ones(V_smpl.shape)/2)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd1, pcd2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mesh.vertices = pcd1.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd2, tgt_mesh])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
