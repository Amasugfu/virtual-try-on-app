{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "m_path = os.path.abspath(os.path.join(\"..\\..\"))\n",
    "if m_path not in sys.path:\n",
    "    sys.path.append(m_path)\n",
    "    \n",
    "# from models.rigging.weight_transfer import main\n",
    "from models.rigging.weight_transfer_robust import transfer_weights\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.smplx_.body_models import SMPL\n",
    "\n",
    "smpl = SMPL(\"models/smpl\", gender=\"male\")\n",
    "src_weights = smpl.lbs_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "src_dict_path = \"models/xcloth/no_git_test_data/88-1/88-1.pkl\"\n",
    "\n",
    "with open(src_dict_path, \"rb\") as f:\n",
    "    src_dict = pickle.load(f)\n",
    "\n",
    "pose = src_dict['pose']\n",
    "trans = src_dict['trans']\n",
    "scale = src_dict['scale']\n",
    "\n",
    "with torch.no_grad():\n",
    "    fin_pose= torch.FloatTensor(pose).unsqueeze(0)\n",
    "    verts_T, T, pose_offsets = smpl(\n",
    "        global_orient=fin_pose[:, :3], \n",
    "        body_pose=fin_pose[:, 3:]\n",
    "    )\n",
    "\n",
    "    ret_verts = verts_T.vertices\n",
    "    ret_joints = verts_T.joints\n",
    "\n",
    "    trans_verts = ret_verts.squeeze() #* scale + trans\n",
    "    trans_joints = ret_joints.squeeze() #* scale + trans\n",
    "\n",
    "smpl_mesh = o3d.geometry.TriangleMesh()\n",
    "smpl_mesh.vertices = o3d.utility.Vector3dVector(trans_verts)\n",
    "smpl_mesh.triangles = o3d.utility.Vector3iVector(smpl.faces.astype(int))\n",
    "smpl_mesh.compute_vertex_normals()\n",
    "\n",
    "joints = trans_joints[:24]\n",
    "joints_pt = o3d.geometry.PointCloud()\n",
    "joints_pt.points = o3d.utility.Vector3dVector(joints)\n",
    "joints_pt.colors = o3d.utility.Vector3dVector(np.repeat([[0, 0, 1]], repeats=joints.shape[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([smpl_mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glb_path = \"C:/Users/User/Downloads/smpl_male_blend2.glb\"\n",
    "# glb = o3d.io.read_triangle_mesh(glb_path)\n",
    "\n",
    "# o3d.visualization.draw_geometries([glb, o3d.geometry.LineSet.create_from_triangle_mesh(smpl_mesh)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_mesh_path = \"../no_git_test_data/1-1/smpl1.obj\"\n",
    "target_mesh_path = \"models/xcloth/no_git_test_data/88-1/model_cleaned.obj\"\n",
    "\n",
    "# src_mesh = o3d.io.read_triangle_mesh(source_mesh_path)\n",
    "tgt_mesh = o3d.io.read_triangle_mesh(target_mesh_path, True)\n",
    "# tgt_mesh.compute_vertex_normals()\n",
    "# align with smpl\n",
    "tgt_mesh.vertices = o3d.utility.Vector3dVector(np.asarray(tgt_mesh.vertices) / scale - trans + verts_T.joints[:, 0].cpu().numpy())\n",
    "\n",
    "o3d.visualization.draw_geometries([o3d.geometry.LineSet.create_from_triangle_mesh(smpl_mesh), joints_pt, tgt_mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\fyp-xcloth\\lib\\site-packages\\pytorch3d\\ops\\laplacian_matrices.py:128: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:607.)\n",
      "  L = torch.sparse.FloatTensor(idx, cot.view(-1), (V, V))\n",
      "c:\\Users\\User\\CODE\\FYP\\models\\rigging\\weight_transfer_robust.py:137: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  Q = -L + L @ M_inv @ L\n"
     ]
    }
   ],
   "source": [
    "# tgt_weights, v_match, v_no_match = main(smpl_mesh, tgt_mesh, src_weights.cpu().numpy(), threshold_distance=0.5/scale)\n",
    "try:\n",
    "    tgt_weights, v_match, v_no_match = transfer_weights(smpl_mesh, tgt_mesh, src_weights.cpu().numpy(), return_match=True)\n",
    "except:\n",
    "    tgt_weights, v_match, v_no_match = transfer_weights(smpl_mesh, tgt_mesh, src_weights.cpu().numpy(), return_match=True, copy_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.zeros((tgt_weights.shape[0], 3))\n",
    "colors[v_match] = np.array([0., .5, 0.])\n",
    "colors[v_no_match] = np.array([.5, 0., 0])\n",
    "\n",
    "tgt_mesh_seg = o3d.geometry.TriangleMesh(tgt_mesh)\n",
    "tgt_mesh_seg.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "tgt_mesh_seg.triangle_uvs = o3d.utility.Vector2dVector()\n",
    "\n",
    "o3d.visualization.draw_geometries([joints_pt, tgt_mesh_seg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaolin.metrics.trianglemesh import point_to_mesh_distance\n",
    "# from trimesh.triangles import points_to_barycentric\n",
    "\n",
    "# from typing import Tuple\n",
    "\n",
    "# def comupte_transform(\n",
    "#     target: torch.Tensor, \n",
    "#     vertices: torch.Tensor,\n",
    "#     faces: torch.Tensor, \n",
    "#     T: torch.Tensor,\n",
    "#     device: torch.device = torch.device(\"cuda\")\n",
    "# ) -> torch.Tensor:\n",
    "#     \"\"\"compute tranformation matrix for each vertex in the target mesh \n",
    "#     by finding the closest point on the reference faces.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     target : torch.Tensor\n",
    "#         the vertices to compute the transformation for.\n",
    "#         [n, 3]\n",
    "#     vertices : torch.Tensor\n",
    "#         the vertices in 3d position of the reference mesh\n",
    "#         [m, 3]\n",
    "#     faces : torch.Tensor\n",
    "#         the faces in vertex indeice of the reference mesh\n",
    "#         [f, 3]\n",
    "#     T: torch,.Tensor\n",
    "#         the transformation matices of each vertex\n",
    "#         [m, 4, 4]\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     torch.Tensor\n",
    "#         the computed tranformation matrix of shape [n, 4, 4]\n",
    "#     \"\"\"\n",
    "\n",
    "#     face_positions = vertices[faces]\n",
    "#     _, face_ids, _ = point_to_mesh_distance(\n",
    "#         target.to(device=device).unsqueeze(0),\n",
    "#         face_positions.to(device=device).unsqueeze(0))\n",
    "#     face_ids = face_ids.squeeze().to(device=target.device)\n",
    "    \n",
    "#     bary_coords = points_to_barycentric(face_positions[face_ids], target)\n",
    "#     ref_T = T[faces[face_ids]]\n",
    "#     target_T = (bary_coords * ref_T).sum(axis=1)\n",
    "    \n",
    "#     return target_T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt_T = comupte_transform(\n",
    "#     torch.as_tensor(np.asarray(tgt_mesh.vertices)),\n",
    "#     torch.as_tensor(np.asarray(smpl_mesh.vertices)),\n",
    "#     torch.as_tensor(np.asarray(smpl_mesh.triangles, dtype=int)),\n",
    "#     T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriangleMesh with 6890 points and 13776 triangles."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    fin_pose= torch.FloatTensor(pose).unsqueeze(0)\n",
    "    verts_T, TT, pose_offsets_T = smpl()\n",
    "\n",
    "    ret_verts = verts_T.vertices\n",
    "    ret_joints = verts_T.joints\n",
    "\n",
    "    trans_verts = ret_verts.squeeze() #* scale + trans\n",
    "    trans_joints = ret_joints.squeeze() #* scale + trans\n",
    "\n",
    "smpl_mesh_T = o3d.geometry.TriangleMesh()\n",
    "smpl_mesh_T.vertices = o3d.utility.Vector3dVector(trans_verts)\n",
    "smpl_mesh_T.triangles = o3d.utility.Vector3iVector(smpl.faces.astype(int))\n",
    "smpl_mesh_T.compute_vertex_normals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbs(W, T, V, pose_offsets=None, inverse=False):\n",
    "    # if inverse_rotation:\n",
    "    #     view = T.view(-1, 4, 4)\n",
    "    #     rotation = view[:, :3, :3]\n",
    "    #     # translation = view[:, :3, -1]\n",
    "    #     rotation = torch.linalg.inv(rotation)\n",
    "    #     view[:, :3, :3] = rotation\n",
    "    #     # T[:, :3, -1] = translation\n",
    "    if inverse:\n",
    "        T = torch.inverse(T.view(-1, 4, 4))\n",
    "    T = (W @ T.reshape(-1, 16)).view(-1, 4, 4)\n",
    "        \n",
    "    if pose_offsets is not None:\n",
    "        V = V + pose_offsets\n",
    "    V_homo = torch.concat([V, torch.ones((V.shape[0], 1), device=V.device)], dim=-1).unsqueeze(dim=-1)\n",
    "    V_homo = T @ V_homo\n",
    "    return V_homo[:, :3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.xcloth.components.utils import create_o3d_pcd\n",
    "from models.rigging.transform import interpolate_pose_offsets\n",
    "\n",
    "device = \"cuda\"\n",
    "T0 = T.cuda().squeeze()\n",
    "T1 = TT.cuda().squeeze()\n",
    "\n",
    "T_identity = torch.eye(4, device=device)\n",
    "T_identity = T_identity.repeat(24, 1)\n",
    "\n",
    "T2 = torch.clone(T1).view(-1, 4, 4)\n",
    "T2[:, :3, -1] = torch.ones(24, 3)\n",
    "T2 = T2.view(-1, 16)\n",
    "\n",
    "# garment\n",
    "W = torch.as_tensor(tgt_weights, device=device).to(dtype=torch.float32)\n",
    "V = torch.as_tensor(np.asarray(tgt_mesh.vertices), device=device).to(dtype=torch.float32)\n",
    "V_norm = lbs(W, T_identity, V)\n",
    "pose_off2 = torch.as_tensor(interpolate_pose_offsets(smpl_mesh, tgt_mesh, pose_offsets.squeeze().numpy())).to(device=device)\n",
    "\n",
    "V_T = lbs(W, T0, V_norm, pose_offsets=pose_off2)\n",
    "\n",
    "# smpl\n",
    "W_smpl = src_weights.cuda().squeeze()\n",
    "V_smpl = torch.as_tensor(np.asarray(smpl_mesh.vertices), device=device).to(dtype=torch.float32)\n",
    "v_smpl_norm = lbs(W_smpl, T_identity, V_smpl, inverse=True)\n",
    "\n",
    "# results\n",
    "pcd1 = create_o3d_pcd(V_norm.cpu().numpy() - pose_off2.cpu().numpy())\n",
    "pcd1_g = create_o3d_pcd(V_T.cpu().numpy())\n",
    "pcd2 = create_o3d_pcd((v_smpl_norm.cpu() - pose_offsets.squeeze()).numpy(), colors=np.ones(V_smpl.shape)/2)\n",
    "\n",
    "new_mesh = o3d.geometry.TriangleMesh(tgt_mesh)\n",
    "new_mesh.vertices = pcd1.points\n",
    "\n",
    "new_smpl = o3d.geometry.TriangleMesh(smpl_mesh)\n",
    "new_smpl.vertices = pcd2.points\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd1_g, pcd2])\n",
    "o3d.visualization.draw_geometries([new_mesh, o3d.geometry.LineSet.create_from_triangle_mesh(new_smpl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_map = {\n",
    "    \"root\": -1,\n",
    "    \"Pelvis\": 0,\n",
    "    \"L_Hip\": 1,\n",
    "    \"L_Knee\": 4,\n",
    "    \"L_Ankle\": 7,\n",
    "    \"L_Foot\": 10,\n",
    "    \"R_Hip\": 2,\n",
    "    \"R_Knee\": 5,\n",
    "    \"R_Ankle\": 8,\n",
    "    \"R_Foot\": 11,\n",
    "    \"Spine1\": 3,\n",
    "    \"Spine2\": 6,\n",
    "    \"Spine3\": 9,\n",
    "    \"Neck\": 12,\n",
    "    \"Head\": 15,\n",
    "    \"L_Collar\": 13,\n",
    "    \"L_Shoulder\": 16,\n",
    "    \"L_Elbow\": 18,\n",
    "    \"L_Wrist\": 20,\n",
    "    \"L_Hand\": 22,\n",
    "    \"R_Collar\": 14,\n",
    "    \"R_Shoulder\": 17,\n",
    "    \"R_Elbow\": 19,\n",
    "    \"R_Wrist\": 21,\n",
    "    \"R_Hand\": 23,\n",
    "}\n",
    "\n",
    "inverse_joints_map = { j: i for i, j in joints_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data are loaded, start creating Blender stuff\n",
      "glTF import finished in 0.32s\n",
      "21:07:08 | ERROR: Draco mesh compression is not available because library could not be found at c:\\Users\\User\\CODE\\FYP\\4.0\\python\\lib\\site-packages\\extern_draco.dll\n",
      "21:07:09 | INFO: Starting glTF 2.0 export\n",
      "21:07:09 | INFO: Extracting primitive: SMPL-shapes-male\n",
      "21:07:28 | INFO: Primitives created: 1\n",
      "21:07:28 | WARNING: There are more than 4 joint vertex influences.The 4 with highest weight will be used (and normalized).\n",
      "21:07:31 | INFO: Finished glTF 2.0 export in 22.48082447052002 s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FINISHED'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bpy\n",
    "import bmesh\n",
    "\n",
    "test_mesh_path = \"models/data/test_data/assets/smpl_male_blend2.glb\"\n",
    "\n",
    "bpy.ops.wm.read_factory_settings(use_empty=True)\n",
    "bpy.ops.import_scene.gltf(filepath=test_mesh_path)\n",
    "# [print(o.name) for o in bpy.data.objects]\n",
    "\n",
    "# bpy.data.objects[\"SMPL-mesh-male\"].select_set(True)\n",
    "obj = bpy.context.scene.objects[\"SMPL-mesh-male\"]\n",
    "bpy.ops.object.mode_set(mode=\"EDIT\")\n",
    "\n",
    "bm = bmesh.new()\n",
    "bm.from_mesh(obj.data)\n",
    "\n",
    "# clean original \n",
    "bmesh.ops.delete(bm, geom=bm.verts)\n",
    "\n",
    "vertices = np.array(tgt_mesh.vertices)\n",
    "vertices[:, -1] *= -1\n",
    "vertices[:, [1, -1]] = vertices[:, [-1, 1]]\n",
    "faces = np.asarray(tgt_mesh.triangles)\n",
    "\n",
    "# add vertices and faces\n",
    "bm_verts = []\n",
    "bm_verts_id = []\n",
    "for v in vertices:\n",
    "    vert = bm.verts.new(v)\n",
    "    vert.index = len(bm.verts)\n",
    "    bm_verts_id.append(vert.index)\n",
    "    bm_verts.append(vert)\n",
    "    \n",
    "for f in faces:\n",
    "    bm.faces.new([\n",
    "        bm_verts[f[0]],\n",
    "        bm_verts[f[1]],\n",
    "        bm_verts[f[2]]\n",
    "    ])\n",
    "    \n",
    "bm.to_mesh(obj.data)  \n",
    "bm.free()\n",
    "\n",
    "# add sknning weights\n",
    "for g in obj.vertex_groups:\n",
    "    i = joints_map[g.name]\n",
    "    if i == -1:\n",
    "        continue\n",
    "    w = tgt_weights[:, i]\n",
    "    for i, v_id in enumerate(bm_verts_id):\n",
    "        obj.vertex_groups[g.name].add([v_id], w[i], \"REPLACE\")\n",
    "\n",
    "# add color / texture    \n",
    "color_layer_name = \"vertex_colors\"\n",
    "obj.data.vertex_colors.new(name=color_layer_name)\n",
    "color_layer = obj.data.vertex_colors[color_layer_name]\n",
    "\n",
    "inverse_id_map = { v: i for i , v in enumerate(bm_verts_id)}\n",
    "for poly in obj.data.polygons:\n",
    "    for vert_i_poly, vert_i_mesh in enumerate(poly.vertices):  \n",
    "        if vert_i_mesh in inverse_id_map.keys():\n",
    "            vert_i_loop = poly.loop_indices[vert_i_poly]\n",
    "            color_layer.data[vert_i_loop].color = (*colors[inverse_id_map[vert_i_mesh]], 1.)\n",
    "    \n",
    "    \n",
    "# reference from: https://stackoverflow.com/questions/67854896/how-do-i-set-the-base-colour-of-a-material-to-equal-vertex-colours-in-blender-2\n",
    "\n",
    "material_name = \"material0\"\n",
    "material = bpy.data.materials.new(name=material_name)\n",
    "material.use_nodes = True\n",
    "obj.data.materials.append(material)\n",
    "\n",
    "# Get node tree from the material\n",
    "nodes = material.node_tree.nodes\n",
    "principled_bsdf_node = nodes.get(\"Principled BSDF\")\n",
    "\n",
    "# Get Vertex Color Node, create it if it does not exist in the current node tree\n",
    "vertex_color_node = nodes.new(type=\"ShaderNodeVertexColor\")\n",
    "\n",
    "# Set the vertex_color layer we created at the beginning as input\n",
    "vertex_color_node.layer_name = color_layer_name\n",
    "\n",
    "# Link Vertex Color Node \"Color\" output to Principled BSDF Node \"Base Color\" input\n",
    "links = material.node_tree.links\n",
    "link = links.new(vertex_color_node.outputs[0], principled_bsdf_node.inputs[0])\n",
    "\n",
    "obj.data.update()\n",
    "\n",
    "bpy.ops.export_scene.gltf(filepath=f\"{test_mesh_path.split('.')[0]}_edit.glb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:31:03 | ERROR: Draco mesh compression is not available because library could not be found at c:\\Users\\User\\CODE\\FYP\\4.0\\python\\lib\\site-packages\\extern_draco.dll\n",
      "21:31:03 | INFO: Starting glTF 2.0 export\n",
      "21:31:03 | INFO: Extracting primitive: NewMesh\n",
      "21:31:03 | INFO: Primitives created: 1\n",
      "21:31:03 | INFO: Finished glTF 2.0 export in 0.24127554893493652 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.xcloth.components.utils import o3d_to_skinned_glb\n",
    "\n",
    "o3d_to_skinned_glb(tgt_mesh_seg, \"models/data/test_data/assets/test.glb\", armature_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
